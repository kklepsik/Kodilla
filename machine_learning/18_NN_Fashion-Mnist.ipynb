{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aaa75",
   "metadata": {},
   "source": [
    "Preprocessing i wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Wczytanie i podział danych\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images = np.concatenate([train_images, test_images], axis=0)\n",
    "labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=10, stratify=labels\n",
    ")\n",
    "\n",
    "# 3. Preprocessing: normalizacja i reshape\n",
    "X_train = X_train.astype('float32') / 255.0         # Podział pikseli na coś pomiędzy 0-1\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train[..., np.newaxis]  # Kształt: [N, 28, 28, 1]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57882d8",
   "metadata": {},
   "source": [
    "Budowa modelu NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Budowa modelu CNN\n",
    "def build_model():\n",
    "    inp = layers.Input(shape=(28, 28, 1))                                   # Rozmiar obrazka 28 x 28 pikseli i 1 kanal koloru\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5f726",
   "metadata": {},
   "source": [
    "Augmentacja z Keras i Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914bd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 5. Augmentacja: połączenie Keras i Albumentations\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size, keras_gen, alb_pipe):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.keras_gen = keras_gen\n",
    "        self.alb_pipe = alb_pipe\n",
    "        self.indices = np.arange(len(X))\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min((idx + 1) * self.batch_size, len(self.X))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        batch_X = self.X[batch_indices].copy()\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Zastosuj augmentację Keras dla każdego obrazu\n",
    "        for i in range(len(batch_X)):\n",
    "            batch_X[i] = self.keras_gen.random_transform(batch_X[i])\n",
    "            # Albumentations: wymaga formatu [28, 28]\n",
    "            aug = self.alb_pipe(image=batch_X[i].squeeze())['image']\n",
    "            batch_X[i] = aug[..., np.newaxis]\n",
    "\n",
    "        return batch_X, batch_y\n",
    "\n",
    "# Definicja augmentacji\n",
    "keras_gen = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.05\n",
    ")\n",
    "\n",
    "alb_pipe = A.Compose([\n",
    "    A.Rotate(limit=8, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=8, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 30.0), p=0.3)\n",
    "])\n",
    "\n",
    "# 6. Trening z augmentacją i optymalizacją\n",
    "batch_size = 64\n",
    "train_gen = CustomDataGenerator(X_train, y_train, batch_size, keras_gen, alb_pipe)\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=int(np.ceil(len(X_train) / batch_size)),  # Poprawka na TypeError\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5269a56",
   "metadata": {},
   "source": [
    "Ewaluacja i wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Ewaluacja modelu\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Final Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 8. Zapis modelu\n",
    "model.save('fashion_mnist_cnn_augmented.keras')\n",
    "\n",
    "# 9. Interfejs predykcji\n",
    "from tensorflow.keras.models import load_model\n",
    "saved_model = load_model('fashion_mnist_cnn_augmented.keras')\n",
    "\n",
    "labels_map = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "def predict_and_show(img):\n",
    "    if img.max() > 1:\n",
    "        img = img.astype('float32') / 255.0\n",
    "    inp = img[np.newaxis, ..., np.newaxis]\n",
    "    pred = saved_model.predict(inp)\n",
    "    idx = np.argmax(pred)\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Predicted: {idx} - {labels_map[idx]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Przykład użycia\n",
    "for i in range(5):\n",
    "    predict_and_show(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21368ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ML)",
   "language": "python",
   "name": "ml-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
